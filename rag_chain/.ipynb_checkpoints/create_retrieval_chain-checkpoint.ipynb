{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7c80ef1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PromptTemplateRunnable' from 'langchain_core.runnables' (/home/dongwoo/myenv/lib/python3.12/site-packages/langchain_core/runnables/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RunnableMap, PromptTemplateRunnable\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moutput_parsers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StrOutputParser\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'PromptTemplateRunnable' from 'langchain_core.runnables' (/home/dongwoo/myenv/lib/python3.12/site-packages/langchain_core/runnables/__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableMap, PromptTemplateRunnable\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b39ec1a",
   "metadata": {},
   "source": [
    "LLM과 Retriever를 받아 LangChain RAG 체인을 생성합니다.\n",
    "\n",
    "Args:\n",
    "    llm: LLM 모델 (예: ChatOpenAI)\n",
    "    retriever: 벡터스토어에서 만든 retriever 객체\n",
    "\n",
    "Returns:\n",
    "    Runnable 체인 객체 (질문에 대해 RAG 응답을 생성함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320a589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약 프롬프트\n",
    "summary_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "다음 문서를 3문장 이내로 요약해 주세요:\n",
    "\n",
    "문서:\n",
    "{document}\n",
    "\"\"\")\n",
    "\n",
    "# 요약 함수\n",
    "def summarize_documents(llm, docs: List):\n",
    "    summarized = []\n",
    "    for doc in docs:\n",
    "        prompt_value = summary_prompt.format_prompt(document=doc.page_content)\n",
    "        messages = prompt_value.to_messages()\n",
    "        result = llm(messages)\n",
    "        summary = result.content\n",
    "        summarized.append(summary)\n",
    "    return summarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aba52e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필터링 함수 예시: 키워드 기반 필터링\n",
    "def filter_documents_by_keyword(docs: List, keyword: str):\n",
    "    return [doc for doc in docs if keyword.lower() in doc.page_content.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56523aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 RAG 체인 생성\n",
    "def create_custom_rag_with_summary_filter(llm, retriever, keyword: str):\n",
    "    # 질의응답 프롬프트\n",
    "    rag_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    다음은 질문에 관련된 문서 요약입니다:\n",
    "\n",
    "    요약된 문서:\n",
    "    {context}\n",
    "\n",
    "    질문:\n",
    "    {question}\n",
    "\n",
    "    답변:\n",
    "    \"\"\")\n",
    "\n",
    "    def get_context(input):\n",
    "        # 1. 관련 문서 검색\n",
    "        docs = retriever(input[\"question\"])\n",
    "        # 2. 키워드 필터링\n",
    "        filtered_docs = filter_documents_by_keyword(docs, keyword)\n",
    "        # 2.5 Re-Ranking 추가\n",
    "        reranked_docs = rerank_documents(question, filtered_docs)\n",
    "        # 3. 요약\n",
    "        summaries = summarize_documents(llm, filtered_docs)\n",
    "        return {\n",
    "            \"context\": \"\\n\\n\".join(summaries),\n",
    "            \"question\": input[\"question\"]\n",
    "        }\n",
    "    \n",
    "    prompt_runnable = PromptTemplateRunnable(rag_prompt)\n",
    "    output_parser   = StrOutputParser()\n",
    "\n",
    "    rag_chain = (\n",
    "        RunnableMap(get_context)\n",
    "        | prompt_runnable\n",
    "        | llm\n",
    "        | output_parser\n",
    "    )\n",
    "\n",
    "    return rag_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeab7816",
   "metadata": {},
   "source": [
    "입력: {\"question\": \"?\"}\n",
    "\n",
    "   ↓\n",
    "\n",
    "get_context (RunnableMap)\n",
    "\n",
    "   ↓\n",
    "\n",
    "{context: \"...\", question: \"...\"}\n",
    "\n",
    "   ↓\n",
    "\n",
    "rag_prompt.format(...)\n",
    "\n",
    "   ↓\n",
    "\n",
    "LLM에 프롬프트 전달\n",
    "\n",
    "   ↓\n",
    "\n",
    "LLM 응답 (ChatMessage 형태)\n",
    "\n",
    "   ↓\n",
    "   \n",
    "StrOutputParser() → 최종 답변 문자열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addeba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4.1-mini\")  # or gpt-4o\n",
    "# retriever = custom_db.as_retriever(top_k=5) (vectorstore 정의 후 retriever 생성 한 뒤에 이미 사용)\n",
    "keyword = \"제안요청서\"  # 예시: \"제안요청서\"가 포함된 문서만 사용\n",
    "\n",
    "rag_chain = create_custom_rag_with_summary_filter(llm, retriever, keyword)\n",
    "\n",
    "response = rag_chain.invoke({\"question\": \"?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d2331d",
   "metadata": {},
   "source": [
    "1. 사용자 질문이 {\"question\": \"\"} 형태로 입력됨\n",
    "2. RunnableMap(get_context)가 작동해서 retriever가 관련 문서들을 검색\n",
    "3. filter_documents_by_keyword가 문서 중 키워드(예: \"제안요청서\") 포함된 문서만 골라냄\n",
    "4. summarize_documents가 각 문서를 3문장 이내로 요약\n",
    "5. 여러 요약문을 하나의 문자열로 합침\n",
    "최종적으로 { \"context\": \"요약된 문서 내용들\", \"question\": \"?\" } 딕셔너리 반환"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
